{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKOesqlY0yxj3RCwYIlear",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kerriea-star/Advanced/blob/master/Getting_Started_with_KerasNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "KerasNLP is a natural language processing library that supports users through their entire development cycle. Our workflows are built from modular components that have state-of-the-art preset weights and architectures when used out-of-the-box and are easily customizable when more control is needed.\n",
        "\n",
        "This library is an extension of the core Keras API; all high-level modules are Layers or Models.\n",
        "\n",
        "KerasNLP uses the **Keras Core** library to work with any of TensorFlow, Pytorch and Jax. In the guide below, we will use the `jax` backend for training our models, and `tf.data` for efficiently running our input preprocessing. But feel free to mix things up! This guide runs in TensorFlow or PyTorch backends with zero changes, simply update the `KERAS_BACKEND` below.\n",
        "\n",
        "\n",
        "Search Keras documentation...\n",
        "\n",
        "» Developer guides / KerasNLP / Getting Started with KerasNLP\n",
        "Getting Started with KerasNLP\n",
        "Author: Jonathan Bischof\n",
        "Date created: 2022/12/15\n",
        "Last modified: 2023/07/01\n",
        "Description: An introduction to the KerasNLP API.\n",
        "\n",
        " View in Colab • GitHub source\n",
        "\n",
        "Introduction\n",
        "KerasNLP is a natural language processing library that supports users through their entire development cycle. Our workflows are built from modular components that have state-of-the-art preset weights and architectures when used out-of-the-box and are easily customizable when more control is needed.\n",
        "\n",
        "This library is an extension of the core Keras API; all high-level modules are Layers or Models. If you are familiar with Keras, congratulations! You already understand most of KerasNLP.\n",
        "\n",
        "KerasNLP uses the Keras Core library to work with any of TensorFlow, Pytorch and Jax. In the guide below, we will use the jax backend for training our models, and tf.data for efficiently running our input preprocessing. But feel free to mix things up! This guide runs in TensorFlow or PyTorch backends with zero changes, simply update the KERAS_BACKEND below.\n",
        "\n",
        "This guide demonstrates our modular approach using a sentiment analysis example at six levels of complexity:\n",
        "\n",
        "*   Inference with a pretrained classifier\n",
        "\n",
        "*   Fine tuning a pretrained backbone\n",
        "*   Fine tuning with user-controlled preprocessing\n",
        "*   Fine tuning a custom model\n",
        "*   Pretraining a backbone model\n",
        "*   LBuild and train your own transformer from scratch\n",
        "\n",
        "Throughout our guide, we use Professor Keras, the official Keras mascot, as a visual\n",
        "reference for the complexity of the material:\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/keras-nlp/getting_started_guide/prof_keras_evolution.png\" alt=\"drawing\" height=\"250\"/>"
      ],
      "metadata": {
        "id": "PbS4sRVCPb-W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UAMIN0sOpa1",
        "outputId": "d300f654-c483-4f40-c553-f769433c31a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.1/590.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.8/489.8 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade keras-nlp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\" # or \"tensorflow\" or \"torch\"\n",
        "\n",
        "import keras_nlp\n",
        "import keras_core as keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3AU5RFkRjRW",
        "outputId": "dae303c7-c912-438a-fd86-f94e68f9a3ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using JAX backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API quickstart\n",
        "\n",
        "Our highest level API is `keras_nlp.models`. These symbols cover the complete user\n",
        "journey of converting strings to tokens, tokens to dense features, and dense features to\n",
        "task-specific output. For each `XX` architecture (e.g., `Bert`), we offer the following\n",
        "modules:\n",
        "\n",
        "* **Tokenizer**: `keras_nlp.models.XXTokenizer`\n",
        "  * **What it does**: Converts strings to sequences of token ids.\n",
        "  * **Why it's important**: The raw bytes of a string are too high dimensional to be useful\n",
        "    features so we first map them to a small number of tokens, for example `\"The quick brown\n",
        "    fox\"` to `[\"the\", \"qu\", \"##ick\", \"br\", \"##own\", \"fox\"]`.\n",
        "  * **Inherits from**: `keras.layers.Layer`.\n",
        "* **Preprocessor**: `keras_nlp.models.XXPreprocessor`\n",
        "  * **What it does**: Converts strings to a dictionary of preprocessed tensors consumed by\n",
        "    the backbone, starting with tokenization.\n",
        "  * **Why it's important**: Each model uses special tokens and extra tensors to understand\n",
        "    the input such as delimiting input segments and identifying padding tokens. Padding each\n",
        "    sequence to the same length improves computational efficiency.\n",
        "  * **Has a**: `XXTokenizer`.\n",
        "  * **Inherits from**: `keras.layers.Layer`.\n",
        "* **Backbone**: `keras_nlp.models.XXBackbone`\n",
        "  * **What it does**: Converts preprocessed tensors to dense features. *Does not handle\n",
        "    strings; call the preprocessor first.*\n",
        "  * **Why it's important**: The backbone distills the input tokens into dense features that\n",
        "    can be used in downstream tasks. It is generally pretrained on a language modeling task\n",
        "    using massive amounts of unlabeled data. Transferring this information to a new task is a\n",
        "    major breakthrough in modern NLP.\n",
        "  * **Inherits from**: `keras.Model`.\n",
        "* **Task**: e.g., `keras_nlp.models.XXClassifier`\n",
        "  * **What it does**: Converts strings to task-specific output (e.g., classification\n",
        "    probabilities).\n",
        "  * **Why it's important**: Task models combine string preprocessing and the backbone model\n",
        "    with task-specific `Layers` to solve a problem such as sentence classification, token\n",
        "    classification, or text generation. The additional `Layers` must be fine-tuned on labeled\n",
        "    data.\n",
        "  * **Has a**: `XXBackbone` and `XXPreprocessor`.\n",
        "  * **Inherits from**: `keras.Model`.\n",
        "\n",
        "Here is the modular hierarchy for `BertClassifier` (all relationships are compositional):\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/keras-nlp/getting_started_guide/class_diagram.png\" alt=\"drawing\" height=\"300\"/>\n",
        "\n",
        "All modules can be used independently and have a `from_preset()` method in addition to\n",
        "the standard constructor that instantiates the class with **preset** architecture and\n",
        "weights (see examples below)."
      ],
      "metadata": {
        "id": "wjaMHJ1KVZou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "We will use a running example of sentiment analysis of IMDB movie reviews. In this task, we use the text to predict whether the review was positive (`label = 1`) or negative (`label = 0`).\n",
        "\n",
        "We load the data using `keras.utils.text_dataset_from_directory`, which utilizes the powerful `tf.data.Dataset` format for examples."
      ],
      "metadata": {
        "id": "O3ce_k03Vo13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz\n",
        "!# Remove unsupervised examples\n",
        "!rm -r aclImdb/train/unsup"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pe6Fqg0S3X2",
        "outputId": "c849e47b-6c13-4b8a-d2a5-8d0d427e6138"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  20.8M      0  0:00:03  0:00:03 --:--:-- 20.8M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "imdb_train = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size = BATCH_SIZE,\n",
        ")\n",
        "imdb_test = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\",\n",
        "    batch_size = BATCH_SIZE,\n",
        ")\n",
        "\n",
        "# Inspec first review\n",
        "# Format is (review text tensor, label tensor)\n",
        "\n",
        "print(imdb_train.unbatch().take(1).get_single_element())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em4zitA9V_aH",
        "outputId": "197c5a25-8570-4ca2-f39e-96d7ecfc168f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "(<tf.Tensor: shape=(), dtype=string, numpy=b'I always enjoy seeing movies that make you think, and don\\'t just drip-feed the answers to their audience. \"Revolver\" is one of these films, and although many reviewers have stated that it is difficult to follow, with a bit of concentration and an open mind I got it. First time. True, it doesn\\'t compare to other mind-mucks like \"The Usual Suspects\" or \"Memento\", but in its own right its an intelligent and thought-provoking film. <br /><br />Another thing I really liked about this film is how damn beautiful it is. Every scene, every camera angle seems to have been thought about for ages. If you see it you\\'ll know what I mean.<br /><br />So, to conclude... watch it with an open mind and you may enjoy it. If not, well, no-one ever said \"Revolver\" is for everyone. And that\\'s my 2 cents.'>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference with a pretrained classifier\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/keras-nlp/getting_started_guide/prof_keras_beginner.png\" alt=\"drawing\" height=\"250\"/>\n",
        "\n",
        "The highest level module in KerasNLP is a **task**. A **task** is a `keras.Model`\n",
        "consisting of a (generally pretrained) **backbone** model and task-specific layers.\n",
        "Here's an example using `keras_nlp.models.BertClassifier`.\n",
        "\n",
        "**Note**: Outputs are the logits per class (e.g., `[0, 0]` is 50% chance of positive). The output is\n",
        "[negative, positive] for binary classification."
      ],
      "metadata": {
        "id": "VGq8KHlpYdZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = keras_nlp.models.BertClassifier.from_preset(\"bert_tiny_en_uncased_sst2\")\n",
        "# Note: batched inputs expected so must wrap string in iterable\n",
        "classifier.predict([\"I love modular workflows in keras-nlp!\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGF3TRdcWwRH",
        "outputId": "24ab144e-9644-478f-8cf6-6a84e1e3d1d5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/bert_tiny_en_uncased_sst2/v1/vocab.txt\n",
            "\u001b[1m231508/231508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step       \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/bert_tiny_en_uncased_sst2/v1/model.h5\n",
            "\u001b[1m17596448/17596448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.5387032,  1.5418268]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All tasks have a `from_preset` method that constructs a `keras.Model` instance with preset preprocessing, architecture and weights. This means that we can pass raw strings in any format accepted by a `keras.Model` and get output specific to our task.\n",
        "\n",
        "This particular preset is a `\"bert_tiny_uncased_en\"` backbone fine-tuned on `sst2`, another movie review sentiment analysis (this time from Rotten Tomatoes). We use the `tiny` architecture for demo purposes, but larger models are recommended for SoTA performance.\n",
        "\n",
        "Let's evaluate our classifier on the IMDB dataset. You will note we don't need to call `keras.Model.compile` here. All task models like `BertClassifier` ship with compilation defaults, meaning we can just call `keras.Model.evaluate` directly. You can always call compile as normal to override these defaults (e.g. to add new metrics).\n",
        "\n",
        "The output below is [loss, accuracy],"
      ],
      "metadata": {
        "id": "_wcY7xHsZt4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.evaluate(imdb_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-PmlV16Y9G3",
        "outputId": "95b6a72a-0901-47ac-e23c-5fab61a28f19"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m802s\u001b[0m 512ms/step - loss: 0.4632 - sparse_categorical_accuracy: 0.7826\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.46294263005256653, 0.783519983291626]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sXCKf-uoamDO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}