{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcbrWn61j3ujc4RfJg8peP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kerriea-star/Advanced/blob/master/Learning_Decision_Forests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build, train and Evaluate a model with Decision Forests**"
      ],
      "metadata": {
        "id": "RX7cDGPNkOLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Introduction*"
      ],
      "metadata": {
        "id": "nY27MYCblhK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow_decision_forests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX_GvQrQw_Ni",
        "outputId": "ddaaa8e8-88c2-4238-9169-e390c1b6a56b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_decision_forests\n",
            "  Downloading tensorflow_decision_forests-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.5.3)\n",
            "Collecting tensorflow~=2.13.0 (from tensorflow_decision_forests)\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.16.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (0.41.0)\n",
            "Collecting wurlitzer (from tensorflow_decision_forests)\n",
            "  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tensorflow_decision_forests) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tensorflow_decision_forests) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tensorflow_decision_forests) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tensorflow_decision_forests) (1.56.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tensorflow_decision_forests) (3.8.0)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow~=2.13.0->tensorflow_decision_forests)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tensorflow_decision_forests) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tensorflow_decision_forests) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tensorflow_decision_forests) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tensorflow_decision_forests) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tensorflow_decision_forests) (67.7.2)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow~=2.13.0->tensorflow_decision_forests)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow~=2.13.0->tensorflow_decision_forests)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tensorflow_decision_forests) (2.3.0)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow~=2.13.0->tensorflow_decision_forests)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tensorflow_decision_forests) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tensorflow_decision_forests) (0.33.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2022.7.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tensorflow_decision_forests) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tensorflow_decision_forests) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tensorflow_decision_forests) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tensorflow_decision_forests) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tensorflow_decision_forests) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tensorflow_decision_forests) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tensorflow_decision_forests) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tensorflow_decision_forests) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tensorflow_decision_forests) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tensorflow_decision_forests) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tensorflow_decision_forests) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tensorflow_decision_forests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tensorflow_decision_forests) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tensorflow_decision_forests) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tensorflow_decision_forests) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tensorflow_decision_forests) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tensorflow_decision_forests) (3.2.2)\n",
            "Installing collected packages: wurlitzer, typing-extensions, tensorflow-estimator, keras, tensorboard, tensorflow, tensorflow_decision_forests\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.7.1\n",
            "    Uninstalling typing_extensions-4.7.1:\n",
            "      Successfully uninstalled typing_extensions-4.7.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "Successfully installed keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow_decision_forests-1.5.0 typing-extensions-4.5.0 wurlitzer-3.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing TF-DF"
      ],
      "metadata": {
        "id": "velXmcjDlvW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wurlitzer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N49pNkSlyKSx",
        "outputId": "fac68d8c-c892-47e0-debd-1b815c4c6bb9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.10/dist-packages (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wurlitzer is needed to display the detailed training logs in Colabs (when using verbose=2 in the model)"
      ],
      "metadata": {
        "id": "ERhowP9RoHmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import math"
      ],
      "metadata": {
        "id": "QbUeZLFaojC2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.magic import register_line_magic\n",
        "from IPython.display import Javascript\n",
        "from IPython.display import display as ipy_display\n",
        "\n",
        "# Some of the model training logs can cover the full\n",
        "# screen if not compressed to a smaller viewport.\n",
        "# This magic allows setting a max height for a cell\n",
        "@register_line_magic\n",
        "def set_cell_height(size):\n",
        "  ipy_display(\n",
        "      Javascript(\"google.colab.output.setInfameHeight(0, true, {maxHeight: \" + str(size) +\"})\"))"
      ],
      "metadata": {
        "id": "Q4ySK7HcpBtt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the version of TensorFlow Decision Forests\n",
        "print(\"Found TensorFlow Decision Forests v\" + tfdf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiL_Ei7ctAu6",
        "outputId": "ea8f3bd0-ff5d-4ae6-9309-6216830f8820"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found TensorFlow Decision Forests v1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training a Random Forest Model**"
      ],
      "metadata": {
        "id": "PmoNkxpgttgN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section we train, evaluate, analyze and export a multi-class classification Random Forest trained on the Palmer's Penguins dataset"
      ],
      "metadata": {
        "id": "4dYN7gcBt6jo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's assemble the dataset into a csv file (i.e. add the header), and load it:"
      ],
      "metadata": {
        "id": "KzrLM7sruQ0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Dataset\n",
        "!wget -q https://storage.googleapis.com/download.tensorflow.org/data/palmer_penguins/penguins.csv -O /tmp/penguins.csv\n",
        "\n",
        "# load the dataset into a Pandas DataFrame\n",
        "dataset_df = pd.read_csv(\"/tmp/penguins.csv\")\n",
        "\n",
        "# Display the first 3 examples\n",
        "dataset_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "GzGsZYyzuelB",
        "outputId": "bb2dcac6-4122-4a89-8d1a-23bbaafd1e65"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
              "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
              "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
              "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
              "\n",
              "   body_mass_g     sex  year  \n",
              "0       3750.0    male  2007  \n",
              "1       3800.0  female  2007  \n",
              "2       3250.0  female  2007  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-3320720a-fd0d-4159-9ce2-e6d4750e144f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "      <th>island</th>\n",
              "      <th>bill_length_mm</th>\n",
              "      <th>bill_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "      <th>sex</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.1</td>\n",
              "      <td>18.7</td>\n",
              "      <td>181.0</td>\n",
              "      <td>3750.0</td>\n",
              "      <td>male</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.5</td>\n",
              "      <td>17.4</td>\n",
              "      <td>186.0</td>\n",
              "      <td>3800.0</td>\n",
              "      <td>female</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>40.3</td>\n",
              "      <td>18.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>3250.0</td>\n",
              "      <td>female</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3320720a-fd0d-4159-9ce2-e6d4750e144f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-56fb30b0-0987-4896-a92c-a2b3a3b30336\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-56fb30b0-0987-4896-a92c-a2b3a3b30336')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-56fb30b0-0987-4896-a92c-a2b3a3b30336 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3320720a-fd0d-4159-9ce2-e6d4750e144f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3320720a-fd0d-4159-9ce2-e6d4750e144f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains a mix of numerical (e.g bill_depth_mm), categorical(e.g. island) and missing features. TF-DF supports all these feature types natively (differently than NN based models), therefore there is no need for preprocessing in the form of one-hot encoding, normalization or extra is_[present feature.\n",
        "\n",
        "Labels are a bit different:Keras metrics expect integers. The label (species) is stored as string, so let's convert it into an integer."
      ],
      "metadata": {
        "id": "Ik2WNjYBveCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the categorical labels as integers\n",
        "# Details:\n",
        "# This is necessary if your classification label is represented as a\n",
        "# string since Keras expects inter classification labels\n",
        "# When using 'pd_dataframe_to_tf_dataset' (see below) this steo can be skipped.\n",
        "\n",
        "# Name of the column.\n",
        "label = \"species\"\n",
        "\n",
        "classes = dataset_df[label].unique().tolist()\n",
        "print(f\"Label classes: {classes}\")\n",
        "\n",
        "dataset_df[label] = dataset_df[label].map(classes.index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR7L4Pi5wShU",
        "outputId": "450a99fc-9a61-43dd-9379-476c5ff84850"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label classes: ['Adelie', 'Gentoo', 'Chinstrap']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next split the dataset into training and testing"
      ],
      "metadata": {
        "id": "X7obytvRxj8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into a training and testing dataset\n",
        "def split_dataset(dataset, test_ratio=0.30):\n",
        "  \"\"\"Splits a panda dataframe into two.\"\"\"\n",
        "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
        "  return dataset[~test_indices], dataset[test_indices]\n",
        "\n",
        "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4Unu6BGxoiO",
        "outputId": "8f8de4d5-1e6e-400d-9f37-c358ec1dfef5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "239 examples in training, 105 examples for testing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And finally, convert the pandas dataframe (pd.DataFrame) into tensorflow datasets (tf.data.Datasets)"
      ],
      "metadata": {
        "id": "B01JaL2ZysmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label)\n",
        "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=label)"
      ],
      "metadata": {
        "id": "0KTKPgbVy3fZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that pd_dataframe_to_tf_dataset converts string labels to integers if necessary.\n",
        "\n",
        "If you want to create the tf.data.Dataset yourself, there are a couple of things to remember\n",
        "\n",
        "\n",
        "*   The learning algorithms work with a one-epoch dataset and without shuffling\n",
        "*   The batch size does not impact the training algorithm, but a small value might slow down reading the dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "uaAWLQK93aEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model**"
      ],
      "metadata": {
        "id": "MNG9VxB04XOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%set_cell_height 300\n",
        "\n",
        "# Specify the model\n",
        "model_1 = tfdf.keras.RandomForestModel(verbose=2)\n",
        "\n",
        "# Train the model\n",
        "model_1.fit(train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yQRRMuH_4bEa",
        "outputId": "874a9e8d-5cfc-4172-8110-251b5c32e729"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setInfameHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use 2 thread(s) for training\n",
            "Use /tmp/tmpcji3rv1w as temporary training directory\n",
            "Reading training dataset...\n",
            "Training tensor examples:\n",
            "Features: {'island': <tf.Tensor 'data:0' shape=(None,) dtype=string>, 'bill_length_mm': <tf.Tensor 'data_1:0' shape=(None,) dtype=float64>, 'bill_depth_mm': <tf.Tensor 'data_2:0' shape=(None,) dtype=float64>, 'flipper_length_mm': <tf.Tensor 'data_3:0' shape=(None,) dtype=float64>, 'body_mass_g': <tf.Tensor 'data_4:0' shape=(None,) dtype=float64>, 'sex': <tf.Tensor 'data_5:0' shape=(None,) dtype=string>, 'year': <tf.Tensor 'data_6:0' shape=(None,) dtype=int64>}\n",
            "Label: Tensor(\"data_7:0\", shape=(None,), dtype=int64)\n",
            "Weights: None\n",
            "Normalized tensor features:\n",
            " {'island': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data:0' shape=(None,) dtype=string>), 'bill_length_mm': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>), 'bill_depth_mm': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>), 'flipper_length_mm': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_2:0' shape=(None,) dtype=float32>), 'body_mass_g': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_3:0' shape=(None,) dtype=float32>), 'sex': SemanticTensor(semantic=<Semantic.CATEGORICAL: 2>, tensor=<tf.Tensor 'data_5:0' shape=(None,) dtype=string>), 'year': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_4:0' shape=(None,) dtype=float32>)}\n",
            "Training dataset read in 0:00:06.236318. Found 239 examples.\n",
            "Training model...\n",
            "Standard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training gets stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO 23-08-11 13:29:46.4501 UTC kernel.cc:773] Start Yggdrasil model training\n",
            "[INFO 23-08-11 13:29:46.4501 UTC kernel.cc:774] Collect training examples\n",
            "[INFO 23-08-11 13:29:46.4502 UTC kernel.cc:787] Dataspec guide:\n",
            "column_guides {\n",
            "  column_name_pattern: \"^__LABEL$\"\n",
            "  type: CATEGORICAL\n",
            "  categorial {\n",
            "    min_vocab_frequency: 0\n",
            "    max_vocab_count: -1\n",
            "  }\n",
            "}\n",
            "default_column_guide {\n",
            "  categorial {\n",
            "    max_vocab_count: 2000\n",
            "  }\n",
            "  discretized_numerical {\n",
            "    maximum_num_bins: 255\n",
            "  }\n",
            "}\n",
            "ignore_columns_without_guides: false\n",
            "detect_numerical_as_discretized_numerical: false\n",
            "\n",
            "[INFO 23-08-11 13:29:46.4508 UTC kernel.cc:393] Number of batches: 1\n",
            "[INFO 23-08-11 13:29:46.4508 UTC kernel.cc:394] Number of examples: 239\n",
            "[INFO 23-08-11 13:29:46.4509 UTC kernel.cc:794] Training dataset:\n",
            "Number of records: 239\n",
            "Number of columns: 8\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 5 (62.5%)\n",
            "\tCATEGORICAL: 3 (37.5%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 5 (62.5%)\n",
            "\t1: \"bill_depth_mm\" NUMERICAL num-nas:1 (0.41841%) mean:17.1588 min:13.1 max:21.2 sd:1.97883\n",
            "\t2: \"bill_length_mm\" NUMERICAL num-nas:1 (0.41841%) mean:44.1206 min:32.1 max:59.6 sd:5.47384\n",
            "\t3: \"body_mass_g\" NUMERICAL num-nas:1 (0.41841%) mean:4235.61 min:2850 max:6300 sd:809.048\n",
            "\t4: \"flipper_length_mm\" NUMERICAL num-nas:1 (0.41841%) mean:201.391 min:172 max:230 sd:13.8219\n",
            "\t7: \"year\" NUMERICAL mean:2008.03 min:2007 max:2009 sd:0.835396\n",
            "\n",
            "CATEGORICAL: 3 (37.5%)\n",
            "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:4 no-ood-item\n",
            "\t5: \"island\" CATEGORICAL has-dict vocab-size:4 zero-ood-items most-frequent:\"Biscoe\" 116 (48.5356%)\n",
            "\t6: \"sex\" CATEGORICAL num-nas:7 (2.92887%) has-dict vocab-size:3 zero-ood-items most-frequent:\"male\" 120 (51.7241%)\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO 23-08-11 13:29:46.4510 UTC kernel.cc:810] Configure learner\n",
            "[INFO 23-08-11 13:29:46.4513 UTC kernel.cc:824] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"^bill_depth_mm$\"\n",
            "features: \"^bill_length_mm$\"\n",
            "features: \"^body_mass_g$\"\n",
            "features: \"^flipper_length_mm$\"\n",
            "features: \"^island$\"\n",
            "features: \"^sex$\"\n",
            "features: \"^year$\"\n",
            "label: \"^__LABEL$\"\n",
            "task: CLASSIFICATION\n",
            "random_seed: 123456\n",
            "metadata {\n",
            "  framework: \"TF Keras\"\n",
            "}\n",
            "pure_serving_model: false\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 300\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    keep_non_leaf_label_distribution: true\n",
            "    num_candidate_attributes: 0\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "    uplift {\n",
            "      min_examples_in_treatment: 5\n",
            "      split_score: KULLBACK_LEIBLER\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  num_oob_variable_importances_permutations: 1\n",
            "  bootstrap_training_dataset: true\n",
            "  bootstrap_size_ratio: 1\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "  sampling_with_replacement: true\n",
            "}\n",
            "\n",
            "[INFO 23-08-11 13:29:46.4518 UTC kernel.cc:827] Deployment config:\n",
            "cache_path: \"/tmp/tmpcji3rv1w/working_cache\"\n",
            "num_threads: 2\n",
            "try_resume_training: true\n",
            "\n",
            "[INFO 23-08-11 13:29:46.4546 UTC kernel.cc:889] Train model\n",
            "[INFO 23-08-11 13:29:46.4548 UTC random_forest.cc:416] Training random forest on 239 example(s) and 7 feature(s).\n",
            "[INFO 23-08-11 13:29:46.4559 UTC random_forest.cc:802] Training of tree  1/300 (tree index:0) done accuracy:0.943182 logloss:2.04793\n",
            "[INFO 23-08-11 13:29:46.4635 UTC random_forest.cc:802] Training of tree  11/300 (tree index:10) done accuracy:0.953975 logloss:0.375455\n",
            "[INFO 23-08-11 13:29:46.4726 UTC random_forest.cc:802] Training of tree  21/300 (tree index:20) done accuracy:0.970711 logloss:0.233637\n",
            "[INFO 23-08-11 13:29:46.4810 UTC random_forest.cc:802] Training of tree  31/300 (tree index:31) done accuracy:0.970711 logloss:0.0796907\n",
            "[INFO 23-08-11 13:29:46.4866 UTC random_forest.cc:802] Training of tree  41/300 (tree index:41) done accuracy:0.962343 logloss:0.0823358\n",
            "[INFO 23-08-11 13:29:46.4959 UTC random_forest.cc:802] Training of tree  51/300 (tree index:51) done accuracy:0.970711 logloss:0.0810351\n",
            "[INFO 23-08-11 13:29:46.5049 UTC random_forest.cc:802] Training of tree  61/300 (tree index:61) done accuracy:0.970711 logloss:0.0802014\n",
            "[INFO 23-08-11 13:29:46.5106 UTC random_forest.cc:802] Training of tree  71/300 (tree index:71) done accuracy:0.974895 logloss:0.0806262\n",
            "[INFO 23-08-11 13:29:46.5162 UTC random_forest.cc:802] Training of tree  81/300 (tree index:81) done accuracy:0.974895 logloss:0.0832477\n",
            "[INFO 23-08-11 13:29:46.5225 UTC random_forest.cc:802] Training of tree  91/300 (tree index:91) done accuracy:0.974895 logloss:0.0828717\n",
            "[INFO 23-08-11 13:29:46.5272 UTC random_forest.cc:802] Training of tree  101/300 (tree index:101) done accuracy:0.974895 logloss:0.0822287\n",
            "[INFO 23-08-11 13:29:46.5296 UTC random_forest.cc:802] Training of tree  111/300 (tree index:110) done accuracy:0.970711 logloss:0.0821563\n",
            "[INFO 23-08-11 13:29:46.5331 UTC random_forest.cc:802] Training of tree  121/300 (tree index:121) done accuracy:0.970711 logloss:0.0812777\n",
            "[INFO 23-08-11 13:29:46.5364 UTC random_forest.cc:802] Training of tree  131/300 (tree index:131) done accuracy:0.974895 logloss:0.0808033\n",
            "[INFO 23-08-11 13:29:46.5396 UTC random_forest.cc:802] Training of tree  141/300 (tree index:141) done accuracy:0.970711 logloss:0.0832234\n",
            "[INFO 23-08-11 13:29:46.5429 UTC random_forest.cc:802] Training of tree  151/300 (tree index:151) done accuracy:0.970711 logloss:0.0837069\n",
            "[INFO 23-08-11 13:29:46.5511 UTC random_forest.cc:802] Training of tree  161/300 (tree index:153) done accuracy:0.974895 logloss:0.0859937\n",
            "[INFO 23-08-11 13:29:46.5544 UTC random_forest.cc:802] Training of tree  171/300 (tree index:171) done accuracy:0.974895 logloss:0.0869298\n",
            "[INFO 23-08-11 13:29:46.5587 UTC random_forest.cc:802] Training of tree  181/300 (tree index:181) done accuracy:0.974895 logloss:0.0837959\n",
            "[INFO 23-08-11 13:29:46.5623 UTC random_forest.cc:802] Training of tree  191/300 (tree index:190) done accuracy:0.974895 logloss:0.0830772\n",
            "[INFO 23-08-11 13:29:46.5661 UTC random_forest.cc:802] Training of tree  201/300 (tree index:201) done accuracy:0.974895 logloss:0.0822319\n",
            "[INFO 23-08-11 13:29:46.5734 UTC random_forest.cc:802] Training of tree  211/300 (tree index:211) done accuracy:0.974895 logloss:0.082015\n",
            "[INFO 23-08-11 13:29:46.5756 UTC random_forest.cc:802] Training of tree  221/300 (tree index:220) done accuracy:0.974895 logloss:0.0805902\n",
            "[INFO 23-08-11 13:29:46.5806 UTC random_forest.cc:802] Training of tree  231/300 (tree index:231) done accuracy:0.974895 logloss:0.0821138\n",
            "[INFO 23-08-11 13:29:46.5850 UTC random_forest.cc:802] Training of tree  241/300 (tree index:241) done accuracy:0.966527 logloss:0.0821634\n",
            "[INFO 23-08-11 13:29:46.5895 UTC random_forest.cc:802] Training of tree  251/300 (tree index:251) done accuracy:0.966527 logloss:0.0817844\n",
            "[INFO 23-08-11 13:29:46.5938 UTC random_forest.cc:802] Training of tree  261/300 (tree index:260) done accuracy:0.966527 logloss:0.0815358\n",
            "[INFO 23-08-11 13:29:46.6005 UTC random_forest.cc:802] Training of tree  271/300 (tree index:271) done accuracy:0.966527 logloss:0.0817295\n",
            "[INFO 23-08-11 13:29:46.6132 UTC random_forest.cc:802] Training of tree  281/300 (tree index:280) done accuracy:0.966527 logloss:0.0817969\n",
            "[INFO 23-08-11 13:29:46.6159 UTC random_forest.cc:802] Training of tree  291/300 (tree index:291) done accuracy:0.966527 logloss:0.0825794\n",
            "[INFO 23-08-11 13:29:46.6208 UTC random_forest.cc:802] Training of tree  300/300 (tree index:287) done accuracy:0.966527 logloss:0.0827327\n",
            "[INFO 23-08-11 13:29:46.6215 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.966527 logloss:0.0827327\n",
            "[INFO 23-08-11 13:29:46.6227 UTC kernel.cc:926] Export model in log directory: /tmp/tmpcji3rv1w with prefix 54b1583a39474b67\n",
            "[INFO 23-08-11 13:29:46.6360 UTC kernel.cc:944] Save model in resources\n",
            "[INFO 23-08-11 13:29:46.6454 UTC abstract_model.cc:849] Model self evaluation:\n",
            "Number of predictions (without weights): 239\n",
            "Number of predictions (with weights): 239\n",
            "Task: CLASSIFICATION\n",
            "Label: __LABEL\n",
            "\n",
            "Accuracy: 0.966527  CI95[W][0.940416 0.983237]\n",
            "LogLoss: : 0.0827327\n",
            "ErrorRate: : 0.0334728\n",
            "\n",
            "Default Accuracy: : 0.435146\n",
            "Default LogLoss: : 1.04977\n",
            "Default ErrorRate: : 0.564854\n",
            "\n",
            "Confusion Table:\n",
            "truth\\prediction\n",
            "   0    1   2   3\n",
            "0  0    0   0   0\n",
            "1  0  100   0   4\n",
            "2  0    1  87   0\n",
            "3  0    3   0  44\n",
            "Total: 239\n",
            "\n",
            "One vs other classes:\n",
            "\n",
            "[INFO 23-08-11 13:29:46.7030 UTC kernel.cc:1243] Loading model from path /tmp/tmpcji3rv1w/model/ with prefix 54b1583a39474b67\n",
            "[INFO 23-08-11 13:29:46.7489 UTC decision_forest.cc:660] Model loaded with 300 root(s), 3974 node(s), and 7 input feature(s).\n",
            "[INFO 23-08-11 13:29:46.7489 UTC abstract_model.cc:1311] Engine \"RandomForestGeneric\" built\n",
            "[INFO 23-08-11 13:29:46.7490 UTC kernel.cc:1075] Use fast generic engine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained in 0:00:00.337771\n",
            "Compiling model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7cf043e58d30> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7cf043e58d30> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cf03ee74190>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remarks\n",
        "\n",
        "*   No input features are specified. Therefore, all the columns will be used as input features except for the label. The feature used by the model are shown in the training logs and the model_summary()\n",
        "*   DFs consume natively numerical, categorical, categorical-set features and\n",
        "missing values. Numerical features do not need to be normalized. Categorical string values do not need to be encoded in a dictionary.\n",
        "*   No training hyper-parameters are specified. Therefore hyper-parameters will be used. Default hyper-parameters provide reasonable results in most situations.\n",
        "*   Calling compile on the model before the fit is optional. Compile can be used to provide extra evaluation metrics.\n",
        "*   Training algorithms do not need validation sets. If a validation set is provided, it will only be used to show metrics\n",
        "*   Tweak the verbose argument to RandomForestModel to control the amount of displayed training logs. Set verbose=0 to hide most of the logs. Set verbose=2 to show all the logs\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2t9keycoky6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate the model**"
      ],
      "metadata": {
        "id": "ASyW_8qGnG2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's evaluate the model on the test dataset\n",
        "model_1.compile(metrics=[\"accuracy\"])\n",
        "evaluation = model_1.evaluate(test_ds, return_dict=True)\n",
        "print()\n",
        "\n",
        "for name, value in evaluation.items():\n",
        "  print(f\"{name}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXRxsrainKnV",
        "outputId": "c119c697-ee61-4bf8-af9e-3519d89e2efc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 741ms/step - loss: 0.0000e+00 - accuracy: 0.9905\n",
            "\n",
            "loss: 0.0000\n",
            "accuracy: 0.9905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remark: The test accuracy is close to the Out-of-bag accuracy shown in the training logs.\n",
        "\n"
      ],
      "metadata": {
        "id": "niJ4qzEcnwcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the model for TensorFlow Serving\n",
        "# Export the model to the SavedModel format later re-use e.g. TensorFlow Serving\n",
        "model_1.save(\"/tmp/my_save_model\")"
      ],
      "metadata": {
        "id": "2HFRdS_lzpSo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare this model for TensorFlow Serving\n",
        "# Export the model to the SavedModel format later re-use e.g. TensorFlow Serving\n",
        "import os\n",
        "import tempfile\n",
        "import requests\n",
        "\n",
        "MODEL_DIR = \"ML/models/decision_forests\"\n",
        "version = \"1\"\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "\n",
        "# save the model\n",
        "model_1.save(export_path, save_format=\"tf\")\n",
        "print(\"\\nexport_path = {}\".format(export_path))\n",
        "!dir {export_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hsl5nqsDn9bL",
        "outputId": "2632f919-56ab-41c8-9d33-6c3468b0cb16"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "export_path = ML/models/decision_forests/1\n",
            "assets\tfingerprint.pb\tkeras_metadata.pb  saved_model.pb  variables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r decision_forests.zip ML/models/decision_forests"
      ],
      "metadata": {
        "id": "XsuAsO5prLUB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43b2daa6-8e7f-477a-884f-d186bbd85b24"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: ML/models/decision_forests/ (stored 0%)\n",
            "  adding: ML/models/decision_forests/1/ (stored 0%)\n",
            "  adding: ML/models/decision_forests/1/assets/ (stored 0%)\n",
            "  adding: ML/models/decision_forests/1/assets/54b1583a39474b67random_forest_header.pb (deflated 91%)\n",
            "  adding: ML/models/decision_forests/1/assets/54b1583a39474b67header.pb (deflated 29%)\n",
            "  adding: ML/models/decision_forests/1/assets/54b1583a39474b67data_spec.pb (deflated 16%)\n",
            "  adding: ML/models/decision_forests/1/assets/54b1583a39474b67done (stored 0%)\n",
            "  adding: ML/models/decision_forests/1/assets/54b1583a39474b67nodes-00000-of-00001 (deflated 83%)\n",
            "  adding: ML/models/decision_forests/1/fingerprint.pb (stored 0%)\n",
            "  adding: ML/models/decision_forests/1/keras_metadata.pb (deflated 79%)\n",
            "  adding: ML/models/decision_forests/1/saved_model.pb (deflated 86%)\n",
            "  adding: ML/models/decision_forests/1/variables/ (stored 0%)\n",
            "  adding: ML/models/decision_forests/1/variables/variables.index (deflated 46%)\n",
            "  adding: ML/models/decision_forests/1/variables/variables.data-00000-of-00001 (deflated 63%)\n"
          ]
        }
      ]
    }
  ]
}